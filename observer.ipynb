{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Introduction & Problem Statement\n",
    "\n",
    "### 1.1 The Challenge: Inefficiencies and Errors in 911 Call Processing\n",
    "\n",
    "Emergency response relies on the swift and accurate transmission of critical information from 911 callers to dispatchers. Currently, a significant portion of this information is captured through manual data entry by call takers. This process is inherently **slow and prone to human error**. Even minor inaccuracies or delays in capturing details like location, nature of the emergency, and number of people involved can have **critical consequences**, potentially delaying life-saving assistance. The manual nature of this task also places a substantial cognitive load on call takers, especially during high-volume incidents. This can further exacerbate errors and reduce overall efficiency.\n",
    "\n",
    "Specifically, the limitations of manual data entry include:\n",
    "\n",
    "*   **Time Consumption:** Manually typing information takes valuable seconds, delaying the dispatch of emergency services.\n",
    "*   **Error Rate:** Human error is inevitable, leading to inaccurate data that can misdirect responders.\n",
    "*   **Scalability Issues:**  During peak demand, manual processing becomes a bottleneck, impacting response times.\n",
    "*   **Inconsistent Data:**  Different call takers may interpret and record information differently, leading to data inconsistencies.\n",
    "\n",
    "### 1.2 Introducing the AI-Powered Solution: Automated Information Extraction\n",
    "\n",
    "To address these critical challenges, I have developed an AI assistant designed to **automatically extract key information from 911 call transcripts**. This solution leverages the power of Generative AI – specifically, Large Language Models (LLMs) – to process spoken language and identify crucial details.\n",
    "\n",
    "**Our AI assistant performs the following key functions:**\n",
    "\n",
    "*   **Automatic Speech Recognition (ASR):** Transcribes the audio from 911 calls into text. (Note: For this demonstration, I will use pre-existing transcriptions to focus on the AI’s extraction capabilities).\n",
    "\n",
    "*   **Structured Data Output:**  Presents the extracted information in a standardized, machine-readable format (JSON), enabling seamless integration with dispatch systems and other downstream applications.\n",
    "\n",
    "**By automating this process, our solution aims to:**\n",
    "\n",
    "*   **Reduce Response Times:**  Deliver critical information to dispatchers more quickly.\n",
    "*   **Improve Data Accuracy:** Minimize errors associated with manual data entry.\n",
    "*   **Enhance Efficiency:**  Free up call takers to focus on critical communication and support.\n",
    "*   **Enable Data-Driven Insights:**  Provide valuable data for analysis and improvement of emergency response systems.\n",
    "\n",
    "This notebook demonstrates the core functionality of our AI assistant, focusing on the extraction and structuring of information from call transcripts. I believe this technology has the potential to significantly improve the effectiveness and efficiency of emergency response services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Overview\n",
    "![System Overview](assets/swift911.jpg)\n",
    "\n",
    "The following diagram illustrates the overall approach of our AI-powered emergency response system.  Audio from the caller is first transcribed into text using Speech-to-Text (STT) technology. This text is then processed by the \"AI Observer,\" which extracts key information and structures it into predefined fields.  This structured data is then available for use by the 911 operator and can be integrated with other emergency response systems.  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Data Simulation\n",
    "\n",
    "### 2.1 Focused Demonstration: Fire Emergency\n",
    "\n",
    "To keep this notebook concise and focused, I will demonstrate the AI assistant’s functionality using a single incident type: a **Fire Emergency**. While the core AI logic is applicable to other scenarios, focusing on one allows for a streamlined presentation.  Additional incident types and transcripts are available in the project repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 Sample Chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_chat = [\n",
    "    (\"911 Operator\",\"This is 911, emergency center. How may I assist you?\"),\n",
    "    (\"Caller\",\"Hello, we have a fire at the main warehouse!\"),\n",
    "    (\"911 Operator\",\"Okay, stay calm. Can you tell me the exact location of the fire?\"),\n",
    "    (\"Caller\",\"It's at 123 Industrial Drive, near the loading docks.\"),\n",
    "    (\"911 Operator\",\"And what is the wind direction currently?\"),\n",
    "    (\"Caller\",\"It's blowing from south to west, pretty strong.\"),\n",
    "    (\"911 Operator\",\"Are there any injuries reported?\"),\n",
    "    (\"Caller\",\"I think so, I saw one worker running out coughing.\"),\n",
    "    (\"911 Operator\",\"Can you estimate how many?\"),\n",
    "    (\"Caller\",\"Just one that I saw.\"),\n",
    "    (\"911 Operator\",\"What time did the fire start approximately?\"),\n",
    "    (\"Caller\",\"Maybe around 10:30 AM.\"),\n",
    "    (\"911 Operator\",\"Can you describe what caused the fire, or what you see happening?\"),\n",
    "    (\"Caller\",\"It started near some stacked cardboard boxes, it's spreading quickly.\"),\n",
    "    (\"911 Operator\",\"What is your name, please?\"),\n",
    "    (\"Caller\",\"My name is John Smith.\"),\n",
    "    (\"911 Operator\",\"And your badge number?\"),\n",
    "    (\"Caller\",\"It's 789012.\"),\n",
    "    (\"911 Operator\",\"Okay, John Smith, badge 789012.  So, we have a fire at 123 Industrial Drive, wind from south to west, one reported injury, started around 10:30 AM, near cardboard boxes. Is that all correct?\"),\n",
    "    (\"Caller\",\"Yes, that's correct.\"),\n",
    "    (\"911 Operator\", \"Thank you.  Fire services have been dispatched.  Please evacuate the area and stay safe.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Data Schemas and Pydantic Models\n",
    "\n",
    "This section defines the data schemas used to represent incident information, using Pydantic to create clear and structured models. These models will be used to structure the information extracted from the incident transcript and ensure that the data is consistent and valid. The `dispatch_required_fields` attribute in the `FireIncident` model highlights the essential information needed for dispatching emergency services. \n",
    "\n",
    "**Notes:** \n",
    "* The `Incident` base model acts as a fallback. If the AI is unable to determine a more specific incident type (e.g., Fire, Medical Assistance), it will default to the base `Incident` model to ensure a valid data structure. \n",
    "* The `MEDICAL_ASSISTANCE` and `THEFT` models can be seen in the repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Type\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "\n",
    "# Represents the type of incident\n",
    "class IncidentType(str, Enum):\n",
    "    FIRE = \"FIRE\"\n",
    "    MEDICAL_ASSISTANCE = \"MEDICAL_ASSISTANCE\"\n",
    "    THEFT = \"THEFT\"\n",
    "    GENERAL = \"GENERAL\"\n",
    "# Represents the wind direction range\n",
    "class WindDirectionType(str, Enum):\n",
    "    FROM_SOUTH_TO_WEST = \"from South to West\"\n",
    "    FROM_WEST_TO_SOUTH = \"from West to South\"\n",
    "    FROM_SOUTH_TO_NORTH = \"from South to North\"\n",
    "    FROM_NORTH_TO_SOUTH = \"from North to South\"\n",
    "    FROM_EAST_TO_WEST = \"from East to West\"\n",
    "    FROM_WEST_TO_EAST = \"from West to East\"\n",
    "    FROM_NORTH_EAST = \"from North to East\"\n",
    "    FROM_EAST_TO_NORTH = \"from East to North\"\n",
    "\n",
    "    \n",
    "# Base Incident Model\n",
    "class Incident(BaseModel):\n",
    "    incident_type: IncidentType | None = Field(..., description=\"Type of incident\")\n",
    "    caller_name: str | None = Field(..., description=\"Name of the caller reporting the incident\")\n",
    "    caller_badge: int | None = Field(..., description=\"Badge number of the caller\")\n",
    "\n",
    "\n",
    "\n",
    "# A specialized model inheriting from Incident and adding attributes specific to fire incidents\n",
    "class FireIncident(Incident):\n",
    "    location: str | None = Field(..., description=\"Location where the incident occurred\")\n",
    "    wind_direction: WindDirectionType | None = Field(\n",
    "        ...,\n",
    "        description=\"Wind direction range (e.g., 'from south to west')\"\n",
    "    )\n",
    "    injury_count: int |None  = Field(..., description=\"Number of people injured\")\n",
    "    timestamp: str | None = Field(..., description=\"Time of the incident as XX:XX AM or XX:XX PM\")\n",
    "    description: str | None = Field(..., description=\"Detailed description of the incident\")\n",
    "\n",
    "    def is_dispatch_ready(self) -> bool:\n",
    "        required_fields = {\n",
    "            'location': self.location,\n",
    "            'wind_direction': self.wind_direction\n",
    "        }\n",
    "        return all([v is not None for v in required_fields.values()])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Structured Generation with Gemini API\n",
    "\n",
    "This section contains the implementation of structured generation using the Google Gemini API. I’ve chosen a similar design choice to (outlines) [https://github.com/dottxt-ai/outlines] to facilitate easier transition and potential local deployment. I also created an OpenAI API generator which is compatible with OLLAMA in the repo[link].\n",
    "\n",
    "\n",
    "The structured generation pipeline consists of two functions:\n",
    "\n",
    "*   **`create_gemini_generator(model_name, model_class)`:** This function creates a generator function tailored to a specific Gemini model and Pydantic model class. It encapsulates the API client and configuration, allowing for flexible model selection.\n",
    "*   **`generator(prompt, max_tokens, temperature)`:** This function takes a prompt (the incident transcript), and generates a structured output based on the provided Pydantic model. It utilizes the Gemini API to generate content, enforcing the desired output format through the `response_schema` parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "INCIDENT_TYPES_MAP = {\n",
    "    \"FIRE\": FireIncident,\n",
    "    \"GENERAL\":  Incident  # Fallback \n",
    "}\n",
    "\n",
    "def create_gemini_generator(model_name: str, model_class: Type[BaseModel]) -> callable:\n",
    "    \"\"\"\n",
    "    Creates a generator function that uses the Gemini API to generate structured output\n",
    "    based on a Pydantic model.\n",
    "\n",
    "    Args:\n",
    "        model_name: The name of the Gemini model to use.\n",
    "        model_class: The Pydantic model class defining the desired output structure.\n",
    "\n",
    "    Returns:\n",
    "        A generator function that takes a prompt and returns an instance of the model class.\n",
    "    \"\"\"\n",
    "\n",
    "    def generator(prompt: str, max_tokens: int = 100, temperature: float = 0.0):\n",
    "        \"\"\"\n",
    "        Generates structured output using the Gemini API.\n",
    "\n",
    "        Args:\n",
    "            prompt: The prompt to send to the Gemini model.\n",
    "            max_tokens: The maximum number of tokens to generate (not directly used in this implementation).\n",
    "            temperature: The temperature to use for generation (not directly used in this implementation).\n",
    "\n",
    "        Returns:\n",
    "            An instance of the model class, or None if parsing fails.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            client = genai.Client(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "            response = client.models.generate_content(\n",
    "                model=model_name,\n",
    "                contents=prompt,\n",
    "                config={\n",
    "                    'system_instruction':f\"You must respond with a valid JSON object that matches this Pydantic model structure: {model_class.schema_json()}\",\n",
    "                    'response_mime_type': 'application/json',\n",
    "                    'response_schema': model_class,\n",
    "                    'max_output_tokens':max_tokens,\n",
    "                    'temperature':temperature\n",
    "                },\n",
    "            )\n",
    "\n",
    "\n",
    "            # Gemini may return an empty response or have issues parsing\n",
    "            if response:\n",
    "                return response.parsed\n",
    "            else:\n",
    "                raise ValueError(f\"Failed to parse response: {response.text}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating or parsing response: {e}\")\n",
    "            return None\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Orchestration with the Observer Class\n",
    "\n",
    "The `Observer` class acts as the central controller for the information extraction pipeline. It takes a 911 call transcript and processes it to produce structured data ready for dispatch.\n",
    "\n",
    "**Here's how it works:**\n",
    "\n",
    "1. **Transcript Preparation:** Formats the raw messages into a single text with speaker identification.\n",
    "2. **Feature Extraction:** Uses a Gemini LLM to extract key information from the transcript and structure it into a Pydantic model.\n",
    "3. **Incident Type Determination:** Dynamically selects the most appropriate Pydantic model (e.g., `FireIncident`, `MedicalAssistance`) based on the transcript's content, starting with a general `Incident` model.\n",
    "4. **Dispatch Check:** Verifies that all crucial information for dispatching emergency services is present.\n",
    "5. **State Management:** Stores the extracted and refined information in the `current_incident` object.\n",
    "\n",
    "**Key Methods:**\n",
    "\n",
    "*   **`__init__()`:** Initializes the class with pre-configured Gemini generators.\n",
    "*   **`extract_features()`:**  The main method – prepares the transcript, calls the LLM, updates the `current_incident`, and checks dispatch readiness.\n",
    "\n",
    "The system prioritizes flexibility by dynamically adjusting the data structure based on the incident type and ensuring all necessary information is available before dispatch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing import Dict, Any,List\n",
    "\n",
    "OBSERVER_MODEL_NAME =\"gemini-2.0-flash\"\n",
    "\n",
    "OBSERVER_SYSTEM_PROMPT =\"\"\"\n",
    "Extract the fields from the emergency call transcript:\n",
    "\n",
    "Important:\n",
    "- Only fill fields if they are explicitly mentioned else put null\n",
    "- Be precise with the selection\n",
    "\n",
    "\n",
    "Example Input:\n",
    "911 Operator: 911, what's your emergency?\n",
    "\n",
    "Caller: My name is Sarah Jennings. My house is on fire! Please help us!\n",
    "\n",
    "911 Operator: Okay, Sarah, stay calm. Can you give me your address, please?\n",
    "\n",
    "Example Output:\n",
    "{{\n",
    "\"incident_type\": \"Fire\",\n",
    "\"caller_name\": \"Sarah Jennings,\n",
    "}}\n",
    "\n",
    "Now extract from this transcript:\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class Observer:\n",
    "    def __init__(self):\n",
    "        self.incident_generators ={k:create_gemini_generator(OBSERVER_MODEL_NAME,v) for k,v in INCIDENT_TYPES_MAP.items()}\n",
    "        self.current_incident : Incident | None  = None\n",
    "        self.is_dispatch_ready = False\n",
    "\n",
    "    def _perpare_transcript(self, messages:List[BaseMessage|tuple | str]):\n",
    "        \"\"\"\n",
    "        Prepares a coherent transcript string from a list of messages.\n",
    "\n",
    "        This method takes a list of messages (representing the 911 call transcript)\n",
    "        and formats it into a single string, identifying the speaker (Caller or 911 Operator)\n",
    "        for each line.\n",
    "\n",
    "        Args:\n",
    "            messages (List[BaseMessage | str]): A list of messages representing the call transcript.\n",
    "                Each message can be either a Langchain BaseMessage object (with 'type' and 'content' attributes)\n",
    "                or a simple string representing a line of dialogue.\n",
    "\n",
    "        Returns:\n",
    "            str: A coherent transcript string with speaker identification.\n",
    "\n",
    "        Raises:\n",
    "            TypeError: If the input is not a list.\n",
    "\n",
    "        Example:\n",
    "            >>> messages = [\n",
    "            ...     {\"type\": \"human\", \"content\": \"Hello, 911, what's your emergency?\"},\n",
    "            ...     {\"type\": \"ai\", \"content\": \"My house is on fire!\"},\n",
    "            ...     \"Please send help!\"\n",
    "            ... ]\n",
    "            >>> observer._prepare_transcript(messages)\n",
    "            'Caller: Hello, 911, what\\'s your emergency?\\n911 Operator: My house is on fire!\\nCaller: Please send help!'\n",
    "        \"\"\"\n",
    "\n",
    "    \n",
    "        transcript_lines = []\n",
    "        for i, message in enumerate(messages):\n",
    "            if hasattr(message, 'type') and hasattr(message, 'content'):\n",
    "                if message.type in ['human', 'ai']:\n",
    "                    speaker = 'Caller' if message.type == 'human' else '911 Operator'\n",
    "                    transcript_lines.append(f\"{speaker}: {message.content}\")\n",
    "            elif isinstance(message, tuple):\n",
    "                speaker, message = message\n",
    "                transcript_lines.append(f\"{speaker}: {message}\")\n",
    "            elif isinstance(message, str):\n",
    "                speaker = '911 Operator' if i % 2 == 0 else 'Caller'\n",
    "                transcript_lines.append(f\"{speaker}: {message}\")\n",
    "        return '\\n'.join(transcript_lines)\n",
    "    \n",
    "\n",
    "    def extract_features(self, messages: List[BaseMessage| tuple | str]) -> tuple[Any, bool]:\n",
    "        \"\"\"\n",
    "        Extracts structured information from a 911 call transcript.\n",
    "\n",
    "        This method orchestrates the entire information extraction pipeline, including:\n",
    "        - Preparing the transcript.\n",
    "        - Calling the Gemini LLM generator.\n",
    "        - Updating the current incident object.\n",
    "        - Checking for dispatch readiness.\n",
    "\n",
    "        Args:\n",
    "            messages (List[BaseMessage | str]): A list of messages representing the call transcript.\n",
    "\n",
    "        Returns:\n",
    "            tuple[Any, bool]: A tuple containing:\n",
    "                - The updated incident object (containing the extracted information).\n",
    "                - A boolean indicating whether the incident is ready for dispatch.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If any error occurs during the extraction process.\n",
    "\n",
    "        Example:\n",
    "            >>> messages = [\n",
    "            ...     {\"type\": \"human\", \"content\": \"There's a fire at 123 Main Street!\"},\n",
    "            ...     {\"type\": \"ai\", \"content\": \"What is your name?\"},\n",
    "            ...     {\"type\": \"human\", \"content\": \"John Doe\"}\n",
    "            ... ]\n",
    "            >>> incident, is_ready = observer.extract_features(messages)\n",
    "            >>> print(incident.location)\n",
    "            '123 Main Street'\n",
    "            >>> print(is_ready)\n",
    "            True\n",
    "        \"\"\"\n",
    "        try:\n",
    "            transcript = self._perpare_transcript(messages)\n",
    "\n",
    "            # Extract two times if it's first time to pick the right pydantic model which is not needed \n",
    "            # unlees we provided the whole transcpit once. However, it could be more efficient.\n",
    "            if self.current_incident is None: \n",
    "                self.current_incident =Incident(incident_type='GENERAL', caller_name=None, caller_badge=None)\n",
    "                self.extract_features(messages) \n",
    "\n",
    "\n",
    "            \n",
    "            current_incident_type = self.current_incident.incident_type.value\n",
    "\n",
    "            generator = self.incident_generators.get(\n",
    "                current_incident_type,\n",
    "                self.incident_generators[\"GENERAL\"]  # Fallback to general incident\n",
    "            )\n",
    "            \n",
    "            # Generate structured information using pre-compiled generator\n",
    "            extracted_info = generator(\n",
    "                OBSERVER_SYSTEM_PROMPT.format(transcript),\n",
    "                max_tokens=1000,\n",
    "                temperature=0.0,\n",
    "            )\n",
    "            \n",
    "\n",
    "            # Check if the incident type changed\n",
    "            if current_incident_type!=extracted_info.incident_type:\n",
    "                incident_class =INCIDENT_TYPES_MAP[extracted_info.incident_type]\n",
    "                args = {key:None for key in incident_class.model_json_schema()['properties'].keys()} # since the feild required make all args None, and we will fill it later\n",
    "                self.current_incident=incident_class(**args)\n",
    "            \n",
    "            # Update current incident with new information since The LLM somtimes writes null instead of None so we handle it here\n",
    "            for key, value in extracted_info:\n",
    "                if value is not None and hasattr(self.current_incident, key):\n",
    "                    if value =='null': \n",
    "                        value=None\n",
    "                    setattr(self.current_incident, key, value)\n",
    "\n",
    "            # Check if the incident requires dispatch and dispatch readiness\n",
    "            if extracted_info and hasattr(extracted_info, 'is_dispatch_ready'):\n",
    "                self.is_dispatch_ready = extracted_info.is_dispatch_ready()\n",
    "\n",
    "            return self.current_incident, self.is_dispatch_ready\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting features: {e}\")\n",
    "            return Incident(incident_type='GENERAL', caller_name=None, caller_badge=None), self.is_dispatch_ready\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "911 Operator: This is 911, emergency center. How may I assist you?\n",
      "Caller: Hello, we have a fire at the main warehouse!\n",
      "911 Operator: Okay, stay calm. Can you tell me the exact location of the fire?\n",
      "Caller: It's at 123 Industrial Drive, near the loading docks.\n",
      "911 Operator: And what is the wind direction currently?\n",
      "Caller: It's blowing from south to west, pretty strong.\n",
      "911 Operator: Are there any injuries reported?\n",
      "Caller: I think so, I saw one worker running out coughing.\n",
      "911 Operator: Can you estimate how many?\n",
      "Caller: Just one that I saw.\n",
      "911 Operator: What time did the fire start approximately?\n",
      "Caller: Maybe around 10:30 AM.\n",
      "911 Operator: Can you describe what caused the fire, or what you see happening?\n",
      "Caller: It started near some stacked cardboard boxes, it's spreading quickly.\n",
      "911 Operator: What is your name, please?\n",
      "Caller: My name is John Smith.\n",
      "911 Operator: And your badge number?\n",
      "Caller: It's 789012.\n",
      "911 Operator: Okay, John Smith, badge 789012.  So, we have a fire at 123 Industrial Drive, wind from south to west, one reported injury, started around 10:30 AM, near cardboard boxes. Is that all correct?\n",
      "Caller: Yes, that's correct.\n",
      "911 Operator: Thank you.  Fire services have been dispatched.  Please evacuate the area and stay safe.\n"
     ]
    }
   ],
   "source": [
    "# Test the functions\n",
    "observer =Observer()\n",
    "transcript = observer._perpare_transcript(fire_chat)\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(FireIncident(incident_type=<IncidentType.FIRE: 'FIRE'>, caller_name='John Smith', caller_badge=789012, location='123 Industrial Drive', wind_direction=<WindDirectionType.FROM_SOUTH_TO_WEST: 'from South to West'>, injury_count=1, timestamp='10:30 AM', description=\"It started near some stacked cardboard boxes, it's spreading quickly.\"),\n",
       " True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = observer.extract_features(fire_chat)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6 : Simulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ba843c7ad145cb93cbec6552e01785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(), Button(description='Next', style=ButtonStyle())))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "observer = Observer()\n",
    "\n",
    "def simulate_chat(chat):\n",
    "    # Output widget to display messages\n",
    "    output = widgets.Output()\n",
    "\n",
    "    # Button to go to next message\n",
    "    next_button = widgets.Button(description=\"Next\")\n",
    "\n",
    "    # Message index tracker\n",
    "    index = {'i': 0}\n",
    "\n",
    "    def display_next_message(b):\n",
    "        with output:\n",
    "            if index['i'] < len(chat):\n",
    "                role, text = chat[index['i']]\n",
    "                color = \"#DCF8C6\" if role == \"911 Operator\" else \"#E1F5FE\"\n",
    "                align = \"left\" if role == \"911 Operator\" else \"right\"\n",
    "\n",
    "                if (index['i'] + 1) % 2 == 0 and index['i'] > 1:\n",
    "                    incident_data = observer.extract_features(chat[:index['i'] + 1])[0]\n",
    "                    observer_text = \"\"\n",
    "                    for key, value in incident_data.dict().items():\n",
    "                        if value is not None:\n",
    "                            observer_text += f'<span style=\"background-color:#90EE90; padding:2px;\"><b>{key}:</b> {value}</span><br>'\n",
    "                        else:\n",
    "                            observer_text += f'<b>{key}:</b> Not Available<br>'\n",
    "\n",
    "                    observer_role = \"Observer\"\n",
    "                    observer_color = \"#AA4A44\"\n",
    "                    observer_align = \"center\"\n",
    "\n",
    "                    html = f'''\n",
    "                                <div style=\"background:{color}; padding:8px; margin:5px;\n",
    "                                            border-radius:10px; max-width:70%; float:{align}; clear:both;\">\n",
    "                                    <b>{role}:</b> {text}\n",
    "                                </div>\n",
    "                                <div style=\"background:{observer_color}; padding:8px; margin:5px;\n",
    "                                            border-radius:10px; max-width:70%; float:{observer_align}; clear:both;\">\n",
    "                                    <b>{observer_role}:\\n</b> {observer_text}\n",
    "                                </div>\n",
    "                                '''\n",
    "\n",
    "                else:\n",
    "                    html = f'''\n",
    "                                <div style=\"background:{color}; padding:8px; margin:5px;\n",
    "                                            border-radius:10px; max-width:70%; float:{align}; clear:both;\">\n",
    "                                    <b>{role}:</b> {text}\n",
    "                                </div>\n",
    "                                '''\n",
    "\n",
    "                display(widgets.HTML(html))\n",
    "\n",
    "                index['i'] += 1\n",
    "            else:\n",
    "                next_button.disabled = True\n",
    "                display(widgets.HTML(\"<b>End of conversation ✅</b>\"))\n",
    "\n",
    "    # Bind the button\n",
    "    next_button.on_click(display_next_message)\n",
    "\n",
    "    # Initial layout\n",
    "    display(widgets.VBox([output, next_button]))\n",
    "\n",
    "simulate_chat(fire_chat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated a functional AI assistant capable of automatically extracting key information from 911 call transcripts. I’ve created a system that has the potential to significantly reduce response times, improve data accuracy, and enhance the efficiency of emergency response services.  The interactive demonstration highlighted how the system can process conversational data and present structured information in a clear and concise manner.\n",
    "\n",
    "While this notebook focused on a fire emergency scenario, the underlying principles and architecture are readily adaptable to a wide range of incident types.\n",
    "\n",
    "## Future Opportunities\n",
    "\n",
    "Beyond automated information extraction, this AI assistant has the potential to significantly expand its capabilities to further improve emergency response effectiveness. Future enhancements could include:\n",
    "\n",
    "*   **Real-time Translation:**  Providing instant translation of calls from non-English speakers, ensuring clear communication and accurate information gathering.\n",
    "*   **Operator Guidance:**  Providing real-time instructions and prompts to call takers, guiding them through critical questioning and ensuring all necessary information is obtained. This includes suggesting follow-up questions based on the caller's responses.\n",
    "*   **And more ...**\n",
    "\n",
    "\n",
    "## Technical Considerations & Future Optimizations\n",
    "*   **Asynchronous & Streaming Operations:** Implementing asynchronous programming and streaming data transfer could further optimize performance and responsiveness.\n",
    "*   **Caching Mechanisms:** Utilizing caching strategies could reduce API costs and improve response times.\n",
    "\n",
    "*   **Evaluation Metrics:** Defining and tracking key evaluation metrics (e.g., accuracy of information extraction, response time) would enable continuous improvement and optimization of the system.\n",
    "\n",
    "These enhancements demonstrate the potential of this technology to transform emergency response systems and improve outcomes for both callers and responders. I believe this work represents a significant step towards creating a more efficient, accurate, and reliable emergency response infrastructure.\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swift911",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
